---
subtitle: "Aprendizaje Estadístico -  (84:04)"
author: 'Alejandro Verri Kozlowski'
title: 'Práctica 3 - Parte I'
output:
  pdf_document:
    toc: no
    number_sections: no
    latex_engine: xelatex
  bookdown::gitbook: 
    number_sections: no
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(data.table) # data,frame extendido
library(ggthemes) 
library(flextable) # Plot Tables

# Rmarkdown ----


if(!equatags::mathjax_available()){
  equatags::mathjax_install()
}

knitr::opts_chunk$set(out.width="50%",fig.align = "center",eval=TRUE, echo = FALSE, warning = FALSE, size = "small")
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
# Identificar output  ----
out_type <- knitr::opts_knit$get("rmarkdown.pandoc.to")


use_df_printer()
set_flextable_defaults(
  font.size = 10,border.color = "gray",
  padding.bottom = 3,   padding.top = 3,
  padding.left = 4,  padding.right = 4,
  post_process_html = function(x){
    # theme_booktabs(x)  |>
    theme_vanilla(x) |>
      set_table_properties(layout = "autofit") |>
      autofit() |>
      align(align="center",part = "header") |>
      bold(part = "header")  |> 
      fontsize(size = 10, part = "header")|> 
      fontsize(size = 10, part = "body")
  },
  post_process_pdf = function(x){
    # theme_booktabs(x)  |>
      theme_vanilla(x) |>
      set_table_properties(layout = "autofit") |>
      autofit() |>
      align(align="center",part = "header") |>
      bold(part = "header")  |>
      fontsize(size = 9, part = "header")|> 
      fontsize(size = 9, part = "body")
  },
  post_process_docx = function(x){
    theme_vanilla(x) |>
      set_table_properties(layout = "autofit") |>
      autofit() |>
      align(align="center",part = "header") |>
      bold(part = "header")  |>
      fontsize(size = 10, part = "header")|> 
      fontsize(size = 9, part = "body")
  }
) 
```

### Ejercicio 1 {-}

Implementar una función que dado un vector `y` de valores de respuesta y una matriz `X` de valores observados, mediante las ecuaciones normales, calcule el estimador de cuadrados mínimos



### Ejercicio 2 {-}

Se tiene en el archivo `girasol.txt` el rinde de diversas parcelas de girasol (en toneladas) según la
cantidad de dinero invertida en fertilizantes (en miles de pesos).

a Graficar en un diagrama de dispersión inversión vs rinde.
b. Plantear un modelo de regresión lineal simple obtener el estimador de mı́nimos cuadrados.
c. Graficar la recta de regresión obtenida, ¿detecta algo sospechoso?

### Ejercicio 3 {-}

Considerar el archivo abalone.txt que contiene información sobre distintas muestras de abalones. Los atributos están separados por coma, con los siguientes campos: 

- Sexo (categórica): M (masculino), F (femenino) o I (infante).
- Longitud (continua), en milimetros.
- Diametro (continua), en milimetros.
- Altura (continua), en milimetros.
- Peso completo del abalone (continua), en gramos.
- Peso de la carne (continua), en gramos.
- Peso de las vísceras (continua), en gramos.
- Peso del caparazón (continua), en gramos.
- Anillos (discreta).

a. Plantear un modelo de regresión lineal simple para predecir el diámetro en función de la longitud.

b. Observar que el conjunto de datos tiene información del peso total de cada espécimen junto con un desagregado por partes. Ajustar un modelo de regresión múltiple que explique el peso total en función del peso del caparazón, las vı́sceras y la carne.

c. Se trata ahora de establecer una relación entre el peso total y el diámetro del espécimen. Empezar dibujando en un scatter plot ambas variables. Si definimos como `P` al peso total y `D` al diámetro, se consideran los siguientes modelos:

- Modelo lineal simple, $P = b + a\.D + \varepsilon$

- Modelo cuadrático, $P = c + b\.D + a\.D^2 + \varepsilon$

- Modelo cubico sin términos de orden inferior, $P = a\.D^3 + $\varepsilon$

Efectuar en cada caso una regresión y graficar las curvas superpuestas sobre el scatter plot.


### Ejercicio 4 {-}
En este ejercicio se crearán datos simulados y se ajustará un modelo de regresión lineal simple.
 
a) Utilizando la función rnorm, crear un vector x que contenga 100 observaciones provenientes de una distribución $X \sim \mathcal{N}(\mu=0,\,\sigma=1)$
  
```{r echo=TRUE}
X <- rnorm(n=100,mean=0,sd=1)
```
  
b) Utilizando la función rnorm, crear un vector epsilon que contenga 100 observaciones provenientes de una distribución $\Sigma \sim \mathcal{N}(\mu=0,\sigma=0.025)$
   

```{r echo=TRUE}
e <- rnorm(n=100,mean=0,sd=0.025)
```
   
   
c) Usando $x$ y $\varepsilon$, generar un vector acorde al modelo: $y = −1 + 0.5 x + \varepsilon$. ¿Cuál es la longitud del vector y? ¿Cuáles son los valores de $\beta_0$ y $\beta_1$ en el modelo?
  
  
```{r echo=TRUE}
Y <- -1 + 0.5*X +e
```
_La longitud del vector `Y=-1+0.5*X+e` es igual a 100  ya que fue construido como la suma de dos vectores de 100 elementos, y además R tiene sobrecargado el operador suma y permite agregar la constante `1` a cada elemento del vector. Los parámetros $\beta_0$ y $\beta_1$ del modelo son los coeficientes de regresión del modelo, y para este caso resultan $\beta_0=-1$ y $\beta_1=+0.5$_  
  
  d) Realizar un scatterplot y observar la relación entre x e y.
  
```{r }
DT <- data.table(x=X,y=Y)
ggplot(data=DT, aes(x=x, y=y)) + geom_point(color="tomato") + theme_bw()
```
  
e) Ajustar un modelo lineal para predecir y en función de x utilizando el método de cuadrados mı́nimos.

```{r echo=TRUE}
DT <- data.table(x=X,y=Y)
MDL <- lm(data=DT,y~1+x)
b0 <- MDL$coefficients["(Intercept)"]
b1 <- MDL$coefficients["x"]
```

Comparar los valores exactos de $\beta_0$ Y $\beta_1$ con sus estimaciones. 
```{r}
data.table("\\beta_0 / \\hat{\\beta_0}"=-1/b0,"\\beta_1 / \\hat{\\beta_1}"=0.5/b1) |> 
  flextable() |> 
  colformat_double(digits = 8) |> 
  mk_par(i = 1, part = "header",
         value = as_paragraph(
           as_equation(.,width = .1, height = .2)),
         use_dot = TRUE) |>  
  autofit()
```
 
_Los estimadores de $\beta_0$ y $\beta_1$ resultaron $\hat{\beta_0}\approx$ `r b0` y $\hat{\beta_1}\approx$ `r b1`, respectivamente_
  
f) Graficar la recta de cuadrados mı́nimos sobre el gráfico realizado en (d). En otro color graficar la recta Y = −1 + 0,5X. 

```{r }
DT <- data.table(x=X,y=Y)
DTP <- data.table(x=X,y=b0+b1*X)
B0 <- -1
B1 <- 0.5

ggplot() + geom_point(data=DT, aes(x=x, y=y),color="tomato") + geom_line(data=DTP,aes(x=x, y=y),color="red")+ geom_abline(intercept = B0,slope = B1,color="blue") + theme_bw()
```
_Las lineas son prácticamente idénticas y no hay manera de diferenciarlas, tal como se vio en la comparación de los coeficientes_


g) Ajustar un modelo polinomial que prediga y usando $x$ y $x^2$ . 

```{r echo=TRUE}
DT <- data.table(y=Y,x1=X,x2=X^2)
MDL <- lm(data=DT,y~x1+x2)
b0 <- MDL$coefficients["(Intercept)"]
b1 <- MDL$coefficients["x1"]
b2 <- MDL$coefficients["x2"]
```
_Los estimadores de $\beta_0$ y $\beta_1$ ahora resultan en  $\hat{\beta_0}\approx$ `r b0` y $\hat{\beta_1}\approx$ `r b1` respectivamente y se agrega un tercer estimador para el término cuadrático igual a $\hat{\beta_2}\approx$ `r b2`_

```{r}
data.table("\\beta_0/\\hat{\\beta_0}"=-1/b0,"\\beta_1/\\hat{\\beta_1}"=0.5/b1) |> 
  flextable() |> 
  colformat_double(digits = 8) |> 
  mk_par(i = 1, part = "header", value = as_paragraph(as_equation(.,width = .1, height = .2)),use_dot = TRUE) |>  
  autofit()
```


  ¿Encuentra alguna evidencia de que el término cuadrático mejora el ajuste del modelo? 

_No, los estimadores $\hat{\beta_0}\approx$ `r b0` y $\hat{\beta_1}\approx$ `r b1` prácticamente no difieren de los anteriores. _

h) Repetir los ı́tems (a) a (f) modificando los datos generados de manera que haya menos ruido en los datos. Una forma de hacerlo es disminuyendo el valor de la varianza de la distribución normal usada para general el término del error epsilon. 

```{r}
e <- rnorm(n=100,mean=0,sd=0.025/5)
Y <- -1 + 0.5*X + e
DT <- data.table(x=X,y=Y)
MDL <- lm(data=DT,y~1+x)
b0 <- MDL$coefficients["(Intercept)"]
b1 <- MDL$coefficients["x"]
DTP <- data.table(x=X,y=b0+b1*X)
B0 <- -1
B1 <- 0.5

ggplot() + geom_point(data=DT, aes(x=x, y=y),color="plum") + geom_line(data=DTP,aes(x=x, y=y),color="salmon")+ geom_abline(intercept = B0,slope = B1,color="blue") + theme_bw()
```


_Reduciendo la varianza cinco veces $(\varepsilon\sim \mathcal{N}(0,0.005)$,los estimadores de $\beta_0$ y $\beta_1$ ahora resultan en $\hat{\beta_0}\approx$ `r b0` y $\hat{\beta_1}\approx$ `r b1` respectivamente _


```{r}
data.table("\\beta_0 / \\hat{\\beta_0}"=-1/b0,"\\beta_1 / \\hat{\\beta_1}"=0.5/b1) |> 
  flextable() |> 
  colformat_double(digits = 8) |> 
  mk_par(i = 1, part = "header",
         value = as_paragraph(
           as_equation(.,width = .1, height = .2)),
         use_dot = TRUE) |>  
  autofit()
```


i) Repetir los ı́tems (a) a (f) modificando los datos generados de manera que haya más ruido en los datos. Una forma de hacerlo es aumentando el valor de la varianza de la distribución normal usada para general el término del error epsilon. 


```{r }
e <- rnorm(n=100,mean=0,sd=0.25)
Y <- -1 + 0.5*X + 10*e
DT <- data.table(x=X,y=Y)
MDL <- lm(data=DT,y~1+x)
b0 <- MDL$coefficients["(Intercept)"]
b1 <- MDL$coefficients["x"]
DTP <- data.table(x=X,y=b0+b1*X)
B0 <- -1
B1 <- 0.5

ggplot() + geom_point(data=DT, aes(x=x, y=y),color="plum") + geom_line(data=DTP,aes(x=x, y=y),color="salmon")+ geom_abline(intercept = B0,slope = B1,color="blue") + theme_bw()
```


_Aumentando la varianza cinco veces$(\varepsilon\sim \mathcal{N}(0,0.125)$,los estimadores de $\beta_0$ y $\beta_1$ ahora resultan en  $\hat{\beta_0}\approx$ `r b0` y $\hat{\beta_1}\approx$ `r b1` respectivamente _

```{r}
data.table("\\beta_0 / \\hat{\\beta_0}"=-1/b0,"\\beta_1 / \\hat{\\beta_1}"=0.5/b1) |> 
  flextable() |> 
  colformat_double(digits = 8) |> 
  mk_par(i = 1, part = "header",
         value = as_paragraph(
           as_equation(.,width = .1, height = .2)),
         use_dot = TRUE) |>  
  autofit()
```

j) En ambos escenarios, hallar una estimación de la varianza. 

*XXX COMPLETAR XXX*

### Ejercicio 5 {-}

  a) Generar el siguiente modelo: Crear dos vectores de datos  $x_1$ y $x_2$ de tamaño 100 con una distribución $X \sim\mathcal{U}(0,1)$  y crear un vector $y = 2 + 2 ∗ x_1 + 0,3 ∗ x_2 + \varepsilon$, con $\varepsilon$  que contenga 100 observaciones con una distribución $\varepsilon \sim\mathcal{N}(0,1)$. ¿Cuales son los coeficientes de regresión?. 

```{r echo=TRUE}
X1 <- runif(n=100,min=0,max=1)
X2 <- runif(n=100,min=0,max=1)
e <- rnorm(n=100,mean=0,sd=1)
B0 <- 2
B1 <- 2
B2 <- 0.3
Y <- B0+B1*X1+B2*X2+e
```

_Para el modelo propuesto, los coeficientes de regresión son $\beta_0=$ `r B0`, $\beta_1=$ `r B1` y $\beta_2=$ `r B2`_

  c) Estimar la correlación entre $x_1$ y $x_2$

  d) Realizar un scatterplot en el que pueda observarse la relación entre $x_1$ y $x_2$
```{r }
DT <- data.table(x1=X1,x2=X2)
ggplot() + geom_point(data=DT, aes(x=x1, y=x2),color="blue")  + theme_bw()
```
  e) Utilizando los datos generados, ajustar a un modelo lineal para predecir y en función de $x_1$ y $x_2$ , utilizando el método de cuadrados mı́nimos y comparar los valores exactos de $\beta$  con sus valores estimados.
```{r echo=TRUE}
DT <- data.table(x1=X1,x2=X2,y=Y)
MDL <- lm(data=DT,y~x1+x2)
b0 <- MDL$coefficients["(Intercept)"]
b1 <- MDL$coefficients["x1"]
b2 <- MDL$coefficients["x2"]
```
  
  _Los estimadores de los oeficientes de regresión del modelo, resultan en $\hat{\beta_0}=$ `r b0`,$\hat{\beta_0}=$ `r b1` y $\hat{\beta_0}=$ `r b2`_

  
  f) Repetir el inciso a) pero con el siguiente modelo: Crear dos vectores de datos de tamaño 100 x 1 a partir de una distribución uniforme en el intervalo (0, 1), y x 2 = 0,5 ∗ x 1 + rnorm(100)/10 . Crear el vector y = 2 + 2 ∗ x 1 + 0,3 ∗ x 2 + rnorm(100). Comparar los resultados obtenidos con los del ı́tem a. 
    
    
